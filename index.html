<!doctype html>
<html>


<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>reveal.js</title>

    <link rel="stylesheet" href="css/reveal.css">

    <link rel="stylesheet" href="css/theme/serif.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">
    <link rel="stylesheet" href="css/reveal-override.css">


    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
</head>

<body>

    <div class="reveal">
        <div class="slides">

            <section>
                <h1>Welcome to scalability 101</h1>


            </section>

            <section>

                <h1>Block 1: Introduction</h1>
            </section>
            <section>

                <h2>What is scalability?</h2>


                <div>

                    <q>Scalability is the capability of a system, network, or process to handle a growing amount of work, or its potential to be enlarged to accommodate that growth. For example, a system is considered scalable if it is capable of increasing
                        its total output under an increased load when resources (typically hardware) are added.</q>

                </div>
            </section>
            <section>

                <h2>Properties of a system</h2>

                <ul data-state="list1">
                    <style>
                        .list1 {
                            font-size: 70%;
                        }
                    </style>
                    <li> <b>Scalable</b>: a system whose performance improves after adding hardware, proportionally to the capacity added. </li>
                    <li> <b>Resilient or graceful degration</b>: a resilient control system is one that maintains state awareness and an accepted level of operational normalcy in response to disturbances. </li>
                    <li> <b>Distributed</b>: a distributed system is a model in which components located on networked computers communicate and coordinate their actions by passing messages. </li>
                </ul>
            </section>

            <section>

                <h2>Types of systems</h2>

                <ul>
                    <li>
                        Concurrent systems.
                    </li>
                    <li>
                        Parallel systems.
                    </li>
                    <li>
                        Distributed systems.
                    </li>
                </ul>

                <aside class="notes">
                    <p>Concurrent programming, the workload is scheduled in different threads that are time sliced or interleaved.</p>
                    <p>The execution of two blocks never overlaps.</p>
                    <p>In parallel computation execution occurs at the same physical instant. Parallel execution is impossible on a single processor machine</p>
                    <p>Distributed computation involves network traffic to coordinate the workload, and may or may not involve multiprocessor machines. In each machine parallel or concurrent execution could be done. </p>
                </aside>
            </section>


            <section>

                <h2>Evolution of CPU processors.</h2>

                <img data-src="img/cpucores.png" width="70%" />

                <aside class="notes">
                    <p>When CPU manufacturers hit the frequency wall they started to add cores to CPUs to increase CPU power while keeping energy consumption at the same level</p>
                </aside>
            </section>


            <section>

                <h2>Evolution of available RAM memory.</h2>

                <img data-src="img/RAMAvg.png" width="70%" />
            </section>

            <section>

                <h2>Evolution of Global IP traffic.</h2>


                <img data-src="img/iptraffic.png" width="70%" />
            </section>

            <section>

                <h2>Where we deploy applications?</h2>

                <ul>
                    <li>On premise, bare metal.</li>
                    <li>Public cloud, AWS</li>
                    <li>Public cloud, GCP</li>
                    <li>Public cloud, Azure</li>
                    <li>Public cloud, Heroku</li>
                    <li>Private cloud, OpenStack</li>
                    <li>Private cloud, VSphere</li>
                </ul>
                <aside class="notes">
                    Bare metal, we manage our own servers. The cloud. Someone somewhere gave us servers and services for deploying our applications. VM an emulated server Container a glorified processTM
                </aside>
            </section>
            <section>

                <h2>Where we deploy applications?</h2>

                <ul>
                    <li>Container orchestrator, Mesos/Marathon/DCOS</li>
                    <li>Container orchestrator, Kubernetes</li>
                    <li>Container orchestrator, Nomad</li>
                    <li>Container orchestrator, Titus</li>
                </ul>
                <aside class="notes">
                    Bare metal, we manage our own servers. The cloud. Someone somewhere gave us servers and services for deploying our applications. VM an emulated server Container a glorified processTM
                </aside>
            </section>
            <section>

                <h2>Cloud timeline</h2>

                <img data-src="img/cloud_timeline.jpg" width="70%" />
            </section>
            <section>

                <h2>What we deploy?</h2>

                <ul>
                    <li>Virtual Machines. </li>
                    <li>Containers. </li>
                    <li>Code.</li>
                </ul>
                <aside class="notes">
                    We deploy either AMIs, containers or code in a serverless or heroku mode.
                </aside>
            </section>
            <section>

                <h2>Digression: what is a container?</h2>

                <img data-src="img/linux-container.png" width="70%" />
            </section>
            <section>

                <h2>How we deploy?</h2>

                <p><b><i>Snowflake servers</i></b>: an operator copies code in the server and install it and restart services manually. </p>
                <p><b><i>With config management</i></b>: using config management tools like <i>Puppet</i>, <i>Ansible</i>, <i>SaltStack</i>, <i>Chef</i>, <i>Juju</i> we get PhoenixServers. </p>
                <p><b><i>Using immutable infrastructure (golden image)</i></b>: we create an artifact that is never modified while being promoted or deployed between environments.</p>
                <aside class="notes">
                    Benefits of immutable infrastructure?
                </aside>
            </section>
            <section>

                <h2>How we organize deployments??</h2>

                </style>
                <p><b>Deployment day!</b>: after QA, a date is set and that date and time we do the deployment. </p>
                <p><b>Continuous deployment/delivery</b>: there is an automated process (a pipeline) that fetch the source code from a commit event, builds it, test it and deploy it. </p>
            </section>
            <section>

                <h2>How we shift traffic?</h2>

                <ul>
                    <li>
                        <p><b>Highlander</b>: kill the old server first, then deploy the new one.</p>
                    </li>
                    <li>
                        <p><b>Rolling upgrade</b>: Replace servers one by one with the new version. </p>
                    </li>
                </ul>
            </section>
            <section>

                <h2>How we shift traffic?</h2>

                <ul>
                    <li>
                        <p><b>Red/black or blue/green</b>: deploy a new server group with the new version, deregister old server group from loadbalancer and register new one. </p>
                    </li>
                    <li>
                        <p><b>Canary release</b>: Deploy a new server group of one server, register the new group without deregistering old one, watch metrics if everything is ok resize new group to target old group size and shrink old one. </p>
                    </li>
                </ul>
            </section>
            <section>

                <h2>How we architecture applications?</h2>

                <ul>
                    <li>
                        <p><b>Monoliths</b>: The whole application is in the same codebase and in the same deployable unit. </p>
                    </li>
                    <li>
                        <p><b>(Micro)services</b>: The service is responsible of a tiny part of the domain responsability (hence the <i>micro</i> prefix), each service is a deployable unit and the communication goes through network.</p>
                    </li>


                </ul>
                <aside class="notes">Dont forget about elegant monolith! complexities for microservices!</aside>
            </section>
            <section>

                <h2>How we architecture applications?</h2>

                <ul>

                    <li>
                        <p><b>Serverless</b>: <q>Applications where some amount of server-side logic is still written but is run in stateless compute containers that are event-triggered, ephemeral, and fully managed by a 3rd party</q> </p>
                    </li>

                </ul>
                <aside class="notes">Dont forget about elegant monolith! complexities for microservices!</aside>
            </section>
            <section>

                <h2>How we do operations?</h2>

                <ul>
                    <li>
                        <p><b>Operations/Sysadmin team</b>: specialized team that handles operations, usually doing oncall shifts, tooling for development teams and deployments</p>
                    </li>
                    <li>
                        <p><b>You build it, you run it </b>: Each team takes responsability for the whole process, from coding to running the software. There are organizational challenges in embracing DevOps methodologies and oncall responsabilities. </p>
                    </li>
                </ul>
            </section>
            <section>

                <h2>Welcome to FooBar enterprises</h2>

                <p>You have been hired as CTO of this company and sole developer of the product.</p>
                <p>The main product of the company is an url-shortener.</p>
                <p>It's for now only an API, no frontend involved, it's expected to receive lots of traffic.</p>
            </section>
            <section>

                <h2>Our tech stack</h2>

                <p>Application written in golang.</p>
                <p>Github for hosting code.</p>
                <p>Cloudformation/Helm to capture infrastructure as code.</p>
                <p>Jenkins as our CI server.</p>
                <p>Spinnaker as our CD tool.</p>
                <p>Kubernetes as our development environment.</p>
                <p>AWS as our production environment.</p>
            </section>

            <section>

                <h2>Our development process</h2>

                <img data-src="img/cicdpipeline.png" width="90%" />
            </section>
            <section>

                <h2>Github</h2>

                <ul>
                    <li>Github is our hosted version control system based on git.</li>
                    <li>Our project is open source and public, if you want to host git privately, you can set up your own git server or more commonly Github Enterprise, Bitbucket or Gitlab.</li>
                    <li>We made an organisation at Github named friendsofscalability, request access there!</li>
                </ul>
            </section>
            <section>

                <h2>Jenkins</h2>

                <ul>

                    <li>CI, continous integration is the practice of build the software on a clean environment to detect build flaws, do integration tests </li>
                    <li>Jenkins is an open source CI server that supports almost every build system.</li>
                    <li>In our case each commit will trigger a webhook that triggers a build on Jenkins of that commit. </li>
                </ul>
            </section>
            <section>

                <h2>Jenkins</h2>

                <ul>

                    <li>Alternatives: TravisCI, CircleCI, TeamCity, GoCD, <a href="https://en.wikipedia.org/wiki/Comparison_of_continuous_integration_software">check out this comparison ...</a> </li>
                    <li>Spinnaker has native integrations with Jenkins and TravisCI, however Travis only provides a hosted version and a enterprise one, so we went for Jenkins.</li>
                    <li>Our jenkins server is at <a href="http://ci.geekshubs.friendsofscalability.com:8080/">http://ci.geekshubs.friendsofscalability.com:8080/</a></li>
                </ul>
            </section>
            <section>

                <h2>Spinnaker</h2>

                <ul>
                    <li>Spinnaker is an open source, multi-cloud continuous delivery platform created by Netflix, with collaborations from Google, Pivotal and other companies.</li>
                    <li>The core of Spinnaker is the ability of creating pipelines.</li>
                    <li>Pipelines codifies the deployment of some application following the immutable infrastructure aproach. </li>
                    <li>Git -> Jenkins -> Spinnaker Pipeline. </li>
                </ul>
            </section>
            <section>

                <h2>Spinnaker</h2>

                <ul>
                    <li>The pipeline could contain several steps but at least, tipically it will have a Bake step for creating the golden image for the application</li>
                    <li>And then a Deploy step, that will deploy this image over some cloud provider (AWS, GCP, Kubernetes)</li>
                    <li>Our Spinnaker setup is at <a href="https://spinnaker.geekshubs.friendsofscalability.com/">https://spinnaker.geekshubs.friendsofscalability.com/</a></li>
                </ul>
            </section>

            <section>

                <h2>AWS</h2>

                <img data-src="img/cloud_market.png" width="80%" />
            </section>
            <section>

                <h2>AWS</h2>

                <ul>
                    <li>In exchange for money, AWS will provide:</li>
                    <ul>
                        <li><b>Compute resources:</b> EC2, ECS, VPCs,Lambda, Security Groups, AutoScaling Groups, ELB, ALB, NLB </li>
                        <li><b>Storage resources:</b> S3, RDS (Databases), DynamoDB, Elasticache </li>
                        <li><b>Security resources:</b> IAM, KMS </li>
                        <li><b>Orchestration:</b> Cloudformation </li>
                        <li><b>Others:</b> ParameterStore, ServiceDiscovery, Kinesis, API Gateway... </li>
                    </ul>
                </ul>
            </section>
            <section>

                <h2>Docker</h2>

                <ul>
                    <li><i>Docker Inc</i> is the company that popularized container usage on 2013 with the docker tool.</li>
                    <li>The docker tool has been including more than just container runtime tools, things like swarm o machine</li>
                    <li>Docker now ships a free community edition docker-ce, an enterprise one docer-ee, and is also an open source project moby.</li>
                </ul>
            </section>
            <section>

                <h2>Docker</h2>

                <ul>
                    <li>The OCI initiative aims to a vendor free technology for containers.</li>
                    <ul>
                        <li>container image specification</li>
                        <li>container runtime specification</li>
                        <li>container networking specification</li>
                        <li>container storage specification</li>
                    </ul>
                    <li>After the success of docker several companies built its own container runtime engines, notable ones are rkt from CoreOS or CRI-O from CNCF.</li>
                </ul>

            </section>
            <section>

                <h2>Kubernetes</h2>

                <ul>
                    <li>Container orchestration at Scale, a project that covers running application on containers from end to end.</li>
                    <li>Started at Google, now under the CNCF Foundation, RedHat, CoreOS, Huawei and many other companies contribute to the project managed in the open.</li>
                    <li>Fast paced project, k8s 1.0 started at 2015 - 1.10 03/2018.</li>
                    <li>Can be installed on baremetal, lots of cloud providers offers a managed version (GKE, AKS, EKS..) </li>
                    <li>There is also a local environment cluster project Minikube. </li>

                </ul>

            </section>

            <section>

                <h2>Kubernetes architecture</h2>

                <img data-src="img/Kubernetes-architecture-unixcloudfusion.png" width="90%" />

            </section>
            <section>

                <h2>Kubernetes basic concepts</h2>

                <table>
                    <colgroup span="2"></colgroup>

                    <tr>
                        <td>Pod</td>
                        <td>Group of containers that lives together</td>
                    </tr>
                    <tr>
                        <td>Service</td>
                        <td>Represents a balancer that expose traffic within the cluster or outside, the selector attribute registers pods.</td>
                    </tr>
                    <tr>
                        <td>Deployment/ReplicaSet</td>
                        <td>It watches the current pods running under the same deployment/replicaset and creates new pods if it doesnt fullfil the specification. </td>
                    </tr>

                </table>
            </section>
            <section>

                <h2>Kubernetes basic concepts</h2>

                <table>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td>ConfigMaps</td>
                        <td>Stores application configuration. </td>
                    </tr>
                    <tr>
                        <td>Secrets</td>
                        <td>Stores application secrets. </td>
                    </tr>
                    <tr>
                        <td>Volumes/PersistentVolumes/StorageClass</td>
                        <td>Defines storages sources that could be used on Deployments/Pods. </td>
                    </tr>
                </table>
            </section>
            <section>

                <h2>Kubernetes basic concepts</h2>

                <table>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td>Ingress.</td>
                        <td>Defines rules (ingress rules) that configures the cluster edge balancer to send traffic from outside directed to an application. </td>
                    </tr>
                    <tr>
                        <td>Nodes.</td>
                        <td>Kubernetes nodes. </td>
                    </tr>

                    <tr>
                        <td>A bunch more.</td>
                        <td>PodPriorities, PodSecurityPolicy, CustomResourceDefinition... </td>
                    </tr>
                </table>
            </section>
            <section>

                <h2>Kubernetes client interaction</h2>

                <ul>
                    <li>Every action is done via the Kubernetes API.</li>
                    <li>Kubernetes controllers follows the <i>Reconciler</i> pattern extensively!.</li>
                    <li>Can interact with API through client libraries or cli (kubectl).</li>
                    <li>Each API object has a definition that could be written over YAML or JSON.</li>
                </ul>
            </section>
            <section>

                <h2>kubectl cheat sheet</h2>

                <table>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td><code>get|describe|edit|explain|delete OBJECT</code> </td>
                        <td>each object accepts the following actions in a CRUD way.</td>
                    </tr>
                    <tr>
                        <td><code>create|replace|apply -f FILE</code> </td>
                        <td>Creates/replaces/applies an object defintion from FILE. </td>
                    </tr>
                </table>
            </section>
            <section>

                <h2>kubectl cheat sheet</h2>

                <table>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td><code>-o yaml|wide|jsonpath|go-template</code></td>
                        <td>Output format for kubectl get commands, wide gives a lot of actual info whereas describe gives a temporal set of events. </td>
                    </tr>
                    <tr>
                        <td><code>kubectl get|delete pods|svc|... -l LABELKEY=LABELVALUE OBJECT</code></td>
                        <td>applies the kubectl command to whatever pods|servicers or others that matches the labels. </td>
                    </tr>

                </table>
            </section>

            <section>

                <h2>kubectl cheat sheet</h2>

                <p>The kubernetes documentation while not extremely updated, is well written and complete! Check it out the <a href="https://kubernetes.io/docs/reference/kubectl/overview/">kubectl one</a>. </p>
            </section>
            <section>

                <h2>Hands on</h2>

                <ul>
                    <li>It's time for you to finish our onboarding guide deploying our application.</li>
                </ul>
            </section>
            <section>
                <h1>Block 2: Scaling/Loadbalancing</h1>
            </section>
            <section>
                <h2>What do you think about our current application?</h2>
            </section>
            <section>

                <h2>Sprint planning</h2>

                <ul>
                    <li>Set up autoscaling.</li>
                    <li>Set up loadbalancing.</li>
                    <li>Set up config management.</li>
                </ul>
            </section>
            <section>

                <h2>Loadbalancing</h2>

                <img data-src="img/middlelb.png" width="90%" />
                <p style="font-size:14px"><a href="https://blog.envoyproxy.io/introduction-to-modern-network-load-balancing-and-proxying-a57f6ff80236">A summary from the excellent post from Matt Klein</a></p>
            </section>
            <section>

                <h2>Loadbalancing: benefits</h2>

                <table>
                    <thead>Loadbalancer benefits:</thead>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td>Naming abstraction</td>
                        <td>Each client only need to remember loadbalancer address instead of discovering services. Usually via DNS or a client library.</td>
                    </tr>
                    <tr>
                        <td>Fault tolerance</td>
                        <td> It can prevent a faulty backend to receive requests.</td>
                    </tr>
                    <tr>
                        <td>Cost and performance benefits</td>
                        <td> it can keep the network traffic distributed between different datacenters or network routes which improves latency and reduces network costs.</td>
                    </tr>

                </table>
            </section>
            <section>

                <h2>Loadbalancing</h2>

                <table>
                    <thead>Loadbalancer classes by OSI layer.</thead>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td>Layer 4 Balancers</td>
                        <td>"Application protocol" agnostic, move bytes from source to dest. </td>
                    </tr>
                    <tr>
                        <td>Layer 7 Balancers</td>
                        <td> "Application protocol" knowdlege, most typical HTTP ones. </td>
                    </tr>
                </table>
            </section>
            <section>

                <h2>Loadbalancing: classes</h2>

                <table>
                    <thead>Loadbalancer classes:</thead>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td>Middle proxy</td>
                        <td> <img data-src="img/middlelb.png" width="90%" />
                        </td>
                    </tr>
                    <tr>
                        <td>Edge loadbalancer</td>
                        <td><img data-src="img/edgeproxy.png" width="90%" /></td>
                    </tr>

                </table>
            </section>
            <section>

                <h2>Loadbalancing: classes</h2>

                <table>
                    <thead>Loadbalancer classes:</thead>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td>Embedded client library</td>
                        <td><img data-src="img/embeddedlb.png" width="90%" /></td>
                    </tr>
                    <tr>
                        <td>Sidecar proxy</td>
                        <td><img data-src="img/sidecarlb.png" width="90%" /></td>
                    </tr>
                </table>
            </section>
            <section>

                <h2>L7 Loadbalancers: typical features</h2>

                <ul>
                    <li>Service discovery</li>
                    <li>Health checking</li>
                    <li>Load balancing</li>
                    <li>Sticky sessions</li>
                    <li>TLS termination (HTTP/2)</li>
                    <li>Observability
                    </li>
                    <li>Security and DoS mitigation
                    </li>
                </ul>
            </section>
            <section>

                <h2>Loadbalancing algorithms</h2>

                <ul>
                    <li>Round Robin</li>
                    <li>IP:hash</li>
                    <li>Least conn</li>
                    <li>Least latency</li>
                    <li>Weighted Round Robin, Weighted least conn</li>
                </ul>
            </section>
            <section>

                <h2>Loadbalancing takeaways</h2>

                <ul>
                    <li>Networking devices are moving from dedicated hardware to sofware run on commodity software</li>
                    <li>Container and some microservices architectures are moving towards the service mesh pattern. </li>
                </ul>
            </section>

            <section>

                <h2>Service Mesh or sidecar proxy</h2>

                <img data-src="img/servicemesh.png" width="60%" />

            </section>


            <section>

                <h2>Service Mesh: control plane</h2>

                <img data-src="img/servicemeshcontrolplane.png" width="90%" />

            </section>

            <section>

                <h2>Service Mesh implementations</h2>

                <table>
                    <colgroup span="3"></colgroup>
                    <tr>
                        <td>
                            <img data-src="img/istio.png" width="90%" />

                        </td>
                        <td>
                            <img data-src="img/linkerd.jpg" width="70%" />

                        </td>

                        <td>
                            <img data-src="img/envoy.png" width="130%" />

                        </td>
                    </tr>
                </table>
            </section>


            <section>

                <h2>How Istio works</h2>

                <img data-src="img/howistioworks.jpg" width="90%" />

            </section>
            <section>

                <h2>Edge loadbalancers at scale</h2>

                <img data-src="img/lbhabgp.png" width="90%" />
                <ul>
                    <li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44824.pdf">Maglev</a> from Google.</li>
                    <li>NLB from Amazon.</li>
                    <li>Each server talks BGP from <a href="https://www.fastly.com/blog/building-and-scaling-fastly-network-part-1-fighting-fib">Fastly</a></li>
                </ul>

            </section>
            <section>

                <h2>Handling overload</h2>

                <ul>
                    <li>Load shedding by criticality.</li>
                    <li>Graceful degration.</li>
                    <li>Rate limiting.</li>
                    <li>Client side throttling.</li>
                    <li>Client retries.</li>
                </ul>
            </section>
            <section>

                <h2>Handling overload</h2>

                <img data-src="img/4-worker-utilization-load-shedder.svg" width="80%" />
            </section>

            <section>

                <h2>Autoscaling</h2>

                <p>What is autoscaling?</p>
                <table>
                    <colgroup span="2" />
                    <tr>
                        <td> <img data-src="img/capacity-example-diagram.png" width="140%" />
                        </td>
                        <td><img data-src="img/capacity-example-over-diagram.png" width="140%" /></td>

                    </tr>
                </table>
            </section>

            <section>

                <h2>Autoscaling</h2>

                <table>
                    <colgroup span="2" />
                    <tr>
                        <td><img data-src="img/capacity-example-under-diagram.png" width="140%" /></td>
                        <td><img data-src="img/capacity-example-with-as-diagram.png" width="140%" /></td>

                    </tr>
                </table>
            </section>
            <section>

                <h2>AutoscalingGroup</h2>
                <ul>
                    <li>There is always a min capacity and a maximum capacity.</li>
                    <li>Autoscaling will determine if desired capacity will increase or decrease.</li>
                    <li>The logic that dictates that are called scaling policies.</li>


                </ul>



            </section>
            <section>

                <h2>AutoscalingGroup</h2>

                <p style="text-align: center;"><img data-src="img/as-basic-diagram.png" width="60%" style="margin: 0 auto;" /></p>


            </section>
            <section>

                <h2>Scaling policies: simple</h2>
                <ul>
                    <li>You configure an alarm following that triggers when a metric (CPU/Memory/Requests/Messages in queue) pass a threshold.</li>
                    <li>The alarm will trigger an add capacity action (scale up) or reduce capacity action (scale down).</li>
                    <li>There is a cooldown to give enough time to get metrics and reevaluate.</li>
                </ul>
            </section>
            <section>

                <h2>Setting metrics for autoscaling</h2>
                <ul>
                    <li>In AWS, could be anything that triggers the Autoscaling API but Cloudwatch is the default method.</li>
                    <li>In Kubernetes, you get metrics from heapster (
                        <1.9) or from metricsServer (1.9+).</li>

                </ul>
            </section>
            <section>

                <h2>You can always do complex things.</h2>
                <p>Predictive AutoScaling. Use your data to predict your scaling needs.</p>

                <p style="text-align: center;"><img data-src="img/scryer.png" width="30%" style="margin: auto auto;" /></p>
            </section>
            <section>

                <h2>Scaling patterns.</h2>
                <p style="text-align: center;"><img data-src="img/autoscaling_patterns.jpg" width="60%" style="margin: auto auto;" /></p>
            </section>

            <section>

                <h2>Scaling mantra</h2>
                <b style="font-size:2em;">Scale up quickly, scale down slowly.</b>
            </section>
            <section>
                <h2>Writing scalable applications</h2>
                <p>As a "general" guide follow the 12-factor approach.</p>
                <p><i>Trendiness</i> now calls them <i>cloud native</i> applications, however the underlying principles remains the same.</p>
                <p>The 12 factor app manifesto was developed by Heroku circa 2011.</p>
            </section>
            <section>
                <h2>12 Factor apps</h2>
                <table>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td>I. Codebase</td>
                        <td> One codebase tracked in revision control, many deploys</td>
                    </tr>
                    <tr>
                        <td> II. Dependencies</td>
                        <td> Explicitly declare and isolate dependencies</td>
                    </tr>
                    <tr>
                        <td>III. Config Store</td>
                        <td>config in the environment</td>
                    </tr>
                    <tr>
                        <td>IV. Backing services</td>
                        <td>Treat backing services as attached resources</td>
                    </tr>
                    <tr>
                        <td>V. Build, release, run</td>
                        <td>Strictly separate build and run stages</td>

                    </tr>
                </table>
            </section>
            <section>
                <h2>12 Factor apps</h2>
                <table>
                    <colgroup span="2"></colgroup>
                    <tr>

                        <td>VI. Processes</td>
                        <td>Execute the app as one or more stateless processes</td>
                    </tr>
                    <tr>
                        <td>VII. Port binding</td>
                        <td>Export services via port binding</td>
                    </tr>
                    <tr>
                        <td>VIII. Concurrency </td>
                        <td>Scale out via the process model</td>
                    </tr>
                    <tr>
                        <td> IX. Disposability</td>
                        <td>Maximize robustness with fast startup and graceful shutdown</td>
                    </tr>


                    </tr>
                </table>
            </section>
            <section>
                <h2>12 Factor apps</h2>
                <table>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td>X. Dev/prod parity</td>
                        <td>Keep development, staging, and production as similar as possible</td>
                    </tr>
                    <tr>
                        <td>XI. Logs</td>
                        <td>Treat logs as event streams</td>
                    </tr>
                    <tr>
                        <td>XII. Admin processes</td>
                        <td> Run admin/management tasks as one-off processes</td>
                    </tr>

                    </tr>
                </table>
            </section>
            <section>
                <h2>Scaling the DB</h2>
                <ul>
                    <li><b>Follower/leader approach (asynchronous replication)</b></li>
                    <li><b>Multileader</b></li>
                    <li><b>Equal nodes (there are no leaders).</b></li>
                    <li>NoSQL, NewSQL or Relational?</li>
                    <li>(Event) Queues.</li>
                </ul>
            </section>

            <section>
                <h2>Follower/Leader approach</h2>
                <ul>
                    <li>Writes goes to leader, leader keeps state over WAL, journal...</li>
                    <li>Leader updates journal entries to followers, followers reconstruct the state from journal.</li>
                    <li>Follower have the state delayed by N seconds, where N >=0, if N is big enough the follower would stop the replication.</li>
                    <li>to scale the storage, is usual to create several follower/leaders clusters with a shard of the data and one follower/leader cluster that holds the sharding data.</li>
                    <li><b>Open question:</b> What happens when leader goes down?</li>
                </ul>
            </section>

            <section>
                <h2>Equal nodes (there are no leaders)</h2>
                <ul>
                    <li>All the nodes are equal, there are no leader nodes.</li>
                    <li>If the client can connect to one node it would receive the nodes list it can connect.</li>
                    <li>Data is sharded and replicated between the nodes of the cluster. </li>
                </ul>
            </section>
            <section>
                <h2>Multileader</h2>
                <ul>
                    <li>Some traditional relational databases or engines provides multileader capabilities.</li>
                    <li>This is achieved through <i>synchronous</i> replication</li>
                    <li><b>Open question:</b> How conflicts are solved?</li>
                    <li>If one of the multiple leaders goes down what happens?</li>
                </ul>
            </section>
            <section>
                <h2>(Event) Queues</h2>
                <ul>
                    <li>A tipical evolution of microservices architecture.</li>
                    <li>State is persisted on a shared queue, the event queue.</li>
                    <li>The queue is another database, and needs to be scaled.</li>
                    <li>Scale is really sensitive to read/writes throughput and operational excellence of the team.</li>
                </ul>
            </section>
            <section>
                <h2>NoSQL, NewSQL or SQL</h2>
                <p>What are the differences?</p>
            </section>
            <section>
                <h2>CAP theorem</h2>
                <p style="text-align: center;"><img data-src="img/CAP-overview.png" width="60%" style="margin: auto auto;" /></p>
                <p style="font-size:14px">Images taken from this good article by Robert Greiner <a href="http://robertgreiner.com/2014/08/cap-theorem-revisited/">here</a></p>

            </section>
            <section>
                <h2>CAP theorem: CP</h2>
                <p style="text-align: center;"><img data-src="img/CAP-CP.png" width="60%" style="margin: auto auto;" /></p>
                <p style="font-size:14px">Images taken from this good article by Robert Greiner <a href="http://robertgreiner.com/2014/08/cap-theorem-revisited/">here</a></p>

            </section>
            <section>
                <h2>CAP theorem: AP</h2>
                <p style="text-align: center;"><img data-src="img/CAP-AP.png" width="60%" style="margin: auto auto;" /></p>
                <p style="font-size:14px">Images taken from this good article by Robert Greiner <a href="http://robertgreiner.com/2014/08/cap-theorem-revisited/">here</a></p>

            </section>

            <section>
                <h2>CAP theorem, a modern approach</h2>
                <p style="text-align: center;"><img data-src="img/CAP-critique.bmp" width="60%" style="margin: auto auto;" /></p>
                <p style="font-size:14px">Image extracted from a really interesting <a href="https://arxiv.org/pdf/1509.05393.pdf
                    ">arxiv article</a></p>
                <aside class="notes">
                    In concurrent programming, an operation (or set of operations) is atomic, linearizable, indivisible or uninterruptible if it appears to the rest of the system to occur at once without being interrupted. Atomicity is a guarantee of isolation from interrupts,
                    signals, concurrent processes and threads. It is relevant for thread safety and reentrancy. Additionally, atomic operations commonly have a succeed-or-fail definitionâ€”they either successfully change the state of the system, or have
                    no apparent effect. A write to a variable does not have to be seen instantaneously, however, writes to variables by different processors have to be seen in the same order by all processors. Causal consistency is a weakening model of
                    sequential consistency by categorizing events into those causally related and those that are not. It defines that only write operations that are causally related need to be seen in the same order by all processes.
                </aside>
            </section>
            <section>

                <h2>Database mantra</h2>
                <ul>
                    <li>Maintaining state is hard and a high maintenance operation, avoid it if you can.</b>
                    </li>
                    <li>You need to understand the consistency and operating models of the database you have chosen.</li>
                </ul>
            </section>


            <section>
                <h3>You have read a lot of reddits and subreddits, what about some coding?</h3>
            </section>
            <section>
                <h2>Are we ready for production, now?</h2>
            </section>
            <section>

                <h2>Retrospective actions.</h2>

                <ul>
                    <li>Create new clusters of applications specialized by requests.</li>
                    <li>Set up service discovery.</li>
                    <li>Set up circuit breakers.</li>
                </ul>
            </section>
            <section>

                <h2>Service discovery</h2>
                <p>What is service discovery?</p>
                <ul>
                    <li>Hey, we talked about this in the loadbalancer part.</li>
                    <li>Nginx/server and an autoscaling service.</li>
                </ul>

            </section>

            <section>

                <h2>Service discovery: Usual suspects</h2>
                <table>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td>ZooKeeper from Apache</td>
                        <td>Library clients</td>
                    </tr>
                    <tr>
                        <td>Eureka from Netflix</td>
                        <td>HTTP API</td>
                    </tr>

                    <tr>
                        <td>Etcd from CoreOS</td>
                        <td>HTTP / gRPC API</td>
                    </tr>
                    <tr>
                        <td>Consul from Hashicorp</td>
                        <td>HTTP API</td>
                    </tr>
                    <tr>
                        <td>DNS SRV records</td>
                        <td>DNS clients</td>
                    </tr>


                </table>
            </section>
            <section>

                <h2>Service discovery</h2>
                <ul>
                    <li>They are basically distributed databases. Remember CAP theorem?</li>
                    <li>Some of these databases are tuned for consistency (etcd,consul,ZooKeeper) others for availability (DNS, Eureka)</li>

                    <li>Consistency is not extremely important as long the result contains some live nodes.</li>
                    <li>The client should query the service discovery, ant then loadbalance from the result.</li>
                    <li>Client tipically cache the result, so even if the service discovery is down some request could make progress.</li>
                </ul>
            </section>

            <section>

                <h2>Service discovery: usual client implementations.</h2>
                <ul>
                    <li>Client side loadbalancing library like Ribbon from netflix, Finagle from Twitter and many others..</li>
                    <li>Fetch and <a href="https://github.com/gliderlabs/registrator">service restart</a> (not recommended) </li>
                    <li>Delegate to the service mesh.</li>
                </ul>
            </section>

            <section>

                <h2>Service discovery: DNS SRV</h2>
                <p style="font-size: 2em">Why DNS SRV is a bad idea?</p>
            </section>
            <section>

                <h2>Service brokers: one step more</h2>
                <ul>
                    <li><b>Service discovery</b>: knowing the service we want to use we will get the servers that provide it.</li>
                    <li><b>Service catalog</b>: Listing all services in a queryable catalog that exposes which services provides.</li>
                    <li><b>Service brokers</b>: using a <a href="https://github.com/openservicebrokerapi/servicebroker">(https://github.com/openservicebrokerapi/servicebroker)</a> Broker API, applications could discover and use services described in the catalog.</li>


                </ul>
            </section>

            <section>
                <h2>Circuit breakers pattern</h2>
                <ul>
                    <li>Via service discovery we obtain a list of servers.</li>
                    <li>We balance requests between servers.</li>
                    <li>What happens if one of the backends is unhealthy?</li>
                    <li>We should retry the request with another backend if possible.</li>
                    <li>What happens if each backend is down?</li>
                    <li>When is safe to start to using backends again?</li>
                </ul>
            </section>
            <section>
                <h2>Circuit breakers</h2>
                <img data-src="img/circuit-breaker-state1.png" width="70%" />
            </section>
            <section>
                <h2>Circuit breakers: implementations</h2>
                <ul>
                    <li>Hystrix, for Java by Netflix and ported to some other languages by the community.</li>
                    <li>Finagle, for Java/Scala by Twitter.</li>
                    <li>gobreaker, for Go by Sony.</li>
                </ul>
            </section>

            <section>

                <h2>Digression: The consensus problem</h2>
                <p>Some of the service discovery implementations uses underneath a distributed consensus algorithm.</p>
                <p>Reaching agreement is a fundamental problem in distributed computing.</p>
                <p>Most known implementation is Paxos algorithm, an algorithm to reach consensus in a distributed system with network faults.</p>
                <p>Another one is Raft, which claims to be a simplified and more efficient version of Paxos with the same guarantees.</p>
            </section>


            <section>

                <h2>Digression: The consensus problem</h2>
                <p style="font-size:2em;">Did you visited <a href="http://thesecretlivesofdata.com/raft/">http://thesecretlivesofdata.com/raft/</a> already?</p>

            </section>
            <section>
                <h3>Talk is cheap, show me the code.</h3>
            </section>
            <section>

                <h2>Performance review.</h2>

                <ul>
                    <li>We have improved resiliency, what is left to do?.</li>
                    <li>We need more insights about what is happening.</li>
                    <li>Set up metrics and tracing.</li>
                    <li>Embrace failure: Chaos Engineering.</li>
                </ul>
            </section>
            <section>
                <h2>Observability</h2>
                <p><q>An observable system is one that exposes enough data about itself so that generating information (finding answers to questions yet to be formulated) and easily accessing this information becomes simple.
                </q>
                </p>
                <p style="font-size:14px"><a href="https://medium.com/@copyconstruct/monitoring-in-the-time-of-cloud-native-c87c7a5bfa3e">A summary from the excellent post from Cindy Sridharan</a></p>

            </section>
            <section>
                <h2>Observability</h2>
                <img data-src="img/monitoringinstrumentation.png" width="70%" />
            </section>
            <section>
                <h2>Black box vs White Box</h2>
                <img data-src="img/blackboxvswhitebox.png" width="70%" />
            </section>

            <section>
                <h2>Monitoring vs observability</h2>
                <img data-src="img/monitoringvsobservability.png" width="70%" />
            </section>
            <section>
                <h2>Monitoring vs observability</h2>
                <img data-src="img/monitoringopsvsdev.png" width="70%" />
            </section>
            <section>
                <h2>Monitoring vs observability</h2>
                <img data-src="img/obssymptomvscause.png" width="70%" />
            </section>

            <section>
                <h2>The three main observability artifacts</h2>
                <ul>
                    <li>logs</li>
                    <li>traces</li>
                    <li>metrics</li>
                </ul>

            </section>
            <section>
                <h2>Logs</h2>
                <p>A log is an immutable record of discrete events that happened over time on plaintext, structured or binary format.</p>
                <p style="text-align: center"><img data-src="img/logs.png" width="50%" /></p>

            </section>
            <section>
                <h2>Traces</h2>
                <p>A trace is a representation of a series of causally-related distributed events that encode the end-to-end request flow through a distributed system.</p>
                <p style="text-align: center"><img data-src="img/traces.png" width="50%" /></p>

            </section>

            <section>
                <h2>Metrics</h2>
                <p>A list of numbers relating to a particular activity, which is recorded at regular periods of time and then studied.</p>
                <p style="text-align: center"><img data-src="img/metricprometheus.png" width="50%" /></p>
            </section>
            <section>
                <h2>A comparison between logs, metrics and traces.</h2>
                <ul>
                    <li>Logs are easy to generate, but costly to process and store.</li>
                    <li>Hard to get information from logs due to the log volume.</li>
                    <li>Metrics processing and storage has a constant overhead.</li>
                    <li>Metrics are also better suited to trigger alerts</li>
                    <li>For tracing to be truly effective, every component in the path of a request needs to be modified to propagate tracing information</li>

                </ul>
            </section>
            <section>
                <h2>Observality phases</h2>
                <p style="text-align: center"><img data-src="img/monitoringapriori.png" width="50%" /></p>

            </section>
            <section>
                <h2>Alerting guidelines</h2>
                <ul>
                    <li>Every time my pager goes off, I should be able to react with a sense of urgency. I can only do this a few times a day before I get fatigued.</li>
                    <li>Every page should be actionable; simply noting "this paged again" is not an action.</li>
                    <li>Every page should require intelligence to deal with: no robotic, scriptable responses.</li>
                </ul>
                <p style="font-size:14px"><a href="https://docs.google.com/document/d/199PqyG3UsyXlwieHaqbGiWVa8eMWi8zzAn0YfcApr8Q/edit#">From My Philosophy on Alerting</a></p>

            </section>

            <section>
                <h2>Observality tooling</h2>
                <ul>
                    <li>Logs.
                        <ul>
                            <li>ELK (ElasticSearch, Logstash, Kibana).</li>
                            <li>EFK (ElasticSearch, Fluentd, Kibana).</li>
                            <li>Graylog, rsyslog</li>
                            <li>SaaS (Splunk, Sumologic).</li>
                        </ul>
                    </li>
                </ul>

            </section>
            <section>
                <h2>Observality tooling</h2>
                <ul>
                    <li>Metrics.
                        <ul>
                            <li>Nagios / Icinga / Sensu.</li>
                            <li>Graphite</li>
                            <li>Prometheus / InfluxDB </li>
                        </ul>
                    </li>
                </ul>

            </section>
            <section>
                <h2>Observality tooling</h2>
                <ul>
                    <li>Tracing.
                        <ul>
                            <li>Zipkin.</li>
                            <li>Opentracing</li>
                            <li>Jaeger </li>
                        </ul>
                    </li>
                </ul>

            </section>
            <section>
                <h2>Chaos Engineering</h2>
                <ol>
                    <li>Start by defining â€˜steady stateâ€™ as some measurable output of a system that indicates normal behavior.</li>
                    <li>Hypothesize that this steady state will continue in both the control group and the experimental group.</li>
                    <li>Introduce variables that reflect real world events like servers that crash, hard drives that malfunction, network connections that are severed, etc.</li>
                    <li>Try to disprove the hypothesis by looking for a difference in steady state between the control group and the experimental group.</li>
                </ol>


            </section>
            <section>
                <h2>Chaos Engineering</h2>
                <ul>
                    <li><b>Chaos</b> doesn't mean random, means disturbance.</li>
                    <li>It's need to be done in production, since traffic and behaviour could differ.</li>
                    <li>Do it with a service you have enough confidence first,<b>don't harm the user.</b>.</li>
                    <li>You need a mechanism to copy or divert some percentage of the traffic.</li>
                </ul>
            </section>
            <section>
                <h2>Chaos Engineering</h2>
                <ul>
                    <li><b>Chaos</b> doesn't mean random, means disturbance.</li>
                    <li>It's need to be done in production, since traffic and behaviour could differ.</li>
                    <li>Do it with a service you have enough confidence first, <b>don't harm the user.</b>.</li>
                    <li>You need a mechanism to copy or divert some percentage of the traffic.</li>
                </ul>
            </section>
            <section>
                <h2>Chaos Engineering: tooling</h2>
                <table>
                    <colgroup span="2"></colgroup>
                    <tr>
                        <td><img data-src="img/netflix_chaos_monkey.jpg" width="60%" /></td>
                        <td><img data-src="img/chaos_kong.png" width="250%" /></td>

                    </tr>
                </table>
            </section>
            <section>
                <h3>Go back to coding, this idea will make you appear on the first page of HackerNews.</h3>
            </section>
            <section>
                <h3>This was fun, what's left? What do you think you can do to improve the setup?</h3>
            </section>
            <section>
                <h2>Extra ball: Incident management</h2>
                <ul>
                    <li>Define an incident management framework.</li>
                    <li>Create a physical or virtual warroom where people involved on the incident can work isolated</li>
                    <li>Appoint an incident commander, which will hold the high state of the incident, an operatinal lead and if needed a communication lead.</li>
                    <li>Create a Live Incident Document where people can follow the state of the incident and write down hypothesys</li>
                    <li>Don't close the incident when is fixed, it's time for postmortem</li>

                </ul>
            </section>
            <section>
                <h2>Post mortem</h2>
                <ul>
                    <li>The objective of the postmortem is to learn why it failed and how to improve, forgot about the who and the blame.</li>
                    <li>The postmortem will probably generate follow-up tasks, don't close the incident until these tasks are done.</li>
                    <li>Hosting a postmortem is an excellent way of learning, invite people from the organisation.</li>
                </ul>
            </section>

            <section>
                <h2>Being on call</h2>
            </section>
        </div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>
        // More info about config & dependencies:
        // - https://github.com/hakimel/reveal.js#configuration
        // - https://github.com/hakimel/reveal.js#dependencies
        Reveal.initialize({
            dependencies: [{
                src: 'plugin/markdown/marked.js'
            }, {
                src: 'plugin/markdown/markdown.js'
            }, {
                src: 'plugin/notes/notes.js',
                async: true
            }, {
                src: 'plugin/highlight/highlight.js',
                async: true,
                callback: function() {
                    hljs.initHighlightingOnLoad();
                }
            }]
        });
        Reveal.configure({
            slideNumber: 'c/t',
            showNotes: false,
            pdfMaxPagesPerSlide: 1,
        });
    </script>
</body>
<footer>
    <script></script>
    <p style="position:absolute; bottom:0px; left:1.8em; font-size: 1em !important;">
        <img src="img/geekshubs.jpeg" width="90px">
    </p>

</footer>

</html>